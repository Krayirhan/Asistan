# ğŸ¤ AI Voice Assistant - RTX 2060 Super Optimized

**8GB VRAM iÃ§in optimize edilmiÅŸ, tamamen aÃ§Ä±k kaynak ve Ã¼cretsiz araÃ§larla Ã§alÄ±ÅŸan akÄ±llÄ± sesli asistan.**

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](LICENSE)
[![VRAM](https://img.shields.io/badge/VRAM-8GB-orange.svg)]()
[![GPU](https://img.shields.io/badge/GPU-RTX%202060%20Super-green.svg)]()

---

## ğŸ“‹ Ã–zellikler

âœ¨ **Ä°letiÅŸim ModlarÄ±**
- âœ… Metin giriÅŸi (konsol veya GUI)
- âœ… Sesli girdi (mikrofon ile konuÅŸma)
- âœ… Wake word aktivasyonu ("Hey Assistant")
- âœ… Metin Ã§Ä±ktÄ±sÄ± (renkli terminal + Markdown)
- âœ… Sesli Ã§Ä±ktÄ± (Kokoro TTS ile doÄŸal TÃ¼rkÃ§e ses)
- âœ… Hybrid mode (hem yazÄ± hem ses)

ğŸ¤– **AI Yetenekleri**
- âœ… AkÄ±llÄ± sohbet (Qwen2.5-3B)
- âœ… GÃ¶rsel anlama (Moondream - "Bu ne?" sorularÄ±)
- âœ… Ä°nternet aramasÄ± (DuckDuckGo entegrasyonu)
- âœ… TÃ¼rkÃ§e-Ä°ngilizce Ã§ift dil
- âœ… KonuÅŸma geÃ§miÅŸi (sliding window)
- âœ… BaÄŸlam anlama

âš¡ **Performans OptimizasyonlarÄ±**
- âœ… GPU Memory Pooling
- âœ… Async Processing
- âœ… Response Caching
- âœ… Auto Model Unload (30s timeout)
- âœ… Mixed Precision (FP16)
- âœ… Lazy Loading

---

## ğŸ› ï¸ Teknik Stack

| BileÅŸen | Model | VRAM KullanÄ±mÄ± |
|---------|-------|----------------|
| **LLM** | Qwen2.5-3B (4-bit) | ~2GB |
| **VLM** | Moondream 0.5B | ~1GB |
| **STT** | Faster-Whisper Medium (INT8) | ~1GB |
| **TTS** | Kokoro-82M (CPU) | 0GB |
| **Wake Word** | Porcupine (CPU) | 0GB |

**Maksimum VRAM KullanÄ±mÄ±:** ~3.5GB / 8GB âœ…

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1ï¸âƒ£ Gereksinimler

```yaml
OS: Windows 10+, Linux, macOS
Python: 3.10 veya 3.11
GPU: NVIDIA RTX 2060 Super (8GB VRAM) veya Ã¼zeri
CUDA: 11.8 veya 12.1
RAM: 16GB (32GB ideal)
Disk: 15GB boÅŸ alan
```

### 2ï¸âƒ£ Ollama Kurulumu

```bash
# Windows (PowerShell - Admin)
winget install Ollama.Ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# macOS
brew install ollama
```

### 3ï¸âƒ£ Modelleri Ä°ndirin

```bash
# LLM - 3B model (hafif ve gÃ¼Ã§lÃ¼)
ollama pull qwen2.5:3b-instruct-q4_K_M

# VLM - GÃ¶rsel analiz
ollama pull moondream

# Test
ollama run qwen2.5:3b-instruct-q4_K_M "Merhaba"
```

### 4ï¸âƒ£ Python OrtamÄ±

```bash
# Virtual environment
python -m venv venv

# Aktive et (Windows)
venv\Scripts\activate

# Aktive et (Linux/Mac)
source venv/bin/activate

# Dependencies
pip install -r requirements.txt
```

### 5ï¸âƒ£ KonfigÃ¼rasyon

```bash
# .env dosyasÄ± oluÅŸtur
copy .env.example .env

# (Opsiyonel) AyarlarÄ± dÃ¼zenle
notepad .env
```

### 6ï¸âƒ£ Ã‡alÄ±ÅŸtÄ±r!

```bash
# Console modu
python src/main.py --mode console

# Sesli mod (Wake word ile)
python src/main.py --mode voice

# Web arayÃ¼zÃ¼
python src/main.py --mode gui
```

---

## ğŸ’¬ KullanÄ±m Ã–rnekleri

### Console Modu

```bash
$ python src/main.py --mode console

ğŸ¤ AI Assistant Ready!
VRAM: 2.3GB / 8GB

You: Merhaba, nasÄ±lsÄ±n?
ğŸ¤– Assistant: Merhaba! Ä°yiyim, teÅŸekkÃ¼r ederim. Size nasÄ±l yardÄ±mcÄ± olabilirim?

You: Python'da liste nasÄ±l oluÅŸturulur?
ğŸ¤– Assistant: Python'da liste oluÅŸturmak iÃ§in kÃ¶ÅŸeli parantez kullanÄ±lÄ±r:

```python
my_list = [1, 2, 3, 4, 5]
names = ["Ali", "AyÅŸe", "Mehmet"]
```

You: /image cat.jpg Bu ne?
ğŸ“¸ GÃ¶rsel analiz ediliyor...
ğŸ¤– Assistant: Bu resimde turuncu renkli, yeÅŸil gÃ¶zlÃ¼ bir kedi gÃ¶rÃ¼yorum...
```

### Sesli Mod

```bash
$ python src/main.py --mode voice

ğŸ¤ Wake Word aktif! "Hey Assistant" deyin...

[KullanÄ±cÄ±: "Hey Assistant"]
ğŸŸ¢ Dinliyorum... (5 saniye konuÅŸun)

[KullanÄ±cÄ± konuÅŸuyor: "BugÃ¼n hava nasÄ±l?"]
ğŸ” Ä°nternet arama...
ğŸ¤– "Ankara'da bugÃ¼n 15 derece ve gÃ¼neÅŸli." [Sesli okuyor]
```

### Web ArayÃ¼zÃ¼ (Gradio)

```bash
$ python src/main.py --mode gui

Running on local URL:  http://127.0.0.1:7860
```

TarayÄ±cÄ±nÄ±zda aÃ§Ä±lÄ±r! ğŸŒ

---

## ğŸ“ Proje YapÄ±sÄ±

```
ai-voice-assistant/
â”œâ”€â”€ config/                    # KonfigÃ¼rasyon dosyalarÄ±
â”‚   â”œâ”€â”€ settings.yaml         # Ana ayarlar
â”‚   â”œâ”€â”€ prompts.yaml          # System promptlar
â”‚   â””â”€â”€ models.yaml           # Model spesifikasyonlarÄ±
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/                 # Ana bileÅŸenler
â”‚   â”‚   â”œâ”€â”€ model_loader.py   # AkÄ±llÄ± model yÃ¶netimi
â”‚   â”‚   â”œâ”€â”€ llm_manager.py    # LLM iÅŸlemleri
â”‚   â”‚   â”œâ”€â”€ memory_manager.py # KonuÅŸma geÃ§miÅŸi
â”‚   â”‚   â””â”€â”€ cache_manager.py  # Response cache
â”‚   â”‚
â”‚   â”œâ”€â”€ audio/                # Ses iÅŸleme
â”‚   â”‚   â”œâ”€â”€ stt_engine.py     # Speech-to-Text
â”‚   â”‚   â”œâ”€â”€ tts_engine.py     # Text-to-Speech
â”‚   â”‚   â”œâ”€â”€ wake_word.py      # Wake word detector
â”‚   â”‚   â””â”€â”€ audio_processor.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                # YardÄ±mcÄ± araÃ§lar
â”‚   â”‚   â”œâ”€â”€ web_search.py     # DuckDuckGo arama
â”‚   â”‚   â”œâ”€â”€ image_handler.py  # GÃ¶rsel iÅŸleme
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                   # KullanÄ±cÄ± arayÃ¼zleri
â”‚   â”‚   â”œâ”€â”€ console_ui.py     # Terminal UI
â”‚   â”‚   â”œâ”€â”€ voice_ui.py       # Sesli UI
â”‚   â”‚   â””â”€â”€ gradio_ui.py      # Web UI
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/           # Ä°zleme
â”‚   â”‚   â”œâ”€â”€ vram_monitor.py   # VRAM takibi
â”‚   â”‚   â”œâ”€â”€ performance.py    # Performans metrikleri
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”‚
â”‚   â””â”€â”€ main.py               # Ana entry point
â”‚
â”œâ”€â”€ tests/                    # Test dosyalarÄ±
â”‚   â”œâ”€â”€ test_vram.py
â”‚   â”œâ”€â”€ test_llm.py
â”‚   â”œâ”€â”€ test_audio.py
â”‚   â””â”€â”€ benchmark.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

## âš™ï¸ KonfigÃ¼rasyon

### Ana Ayarlar (`config/settings.yaml`)

```yaml
# Hardware
hardware:
  gpu_memory_limit: 7.5  # GB
  model_unload_timeout: 30  # saniye
  mixed_precision: true

# LLM
llm:
  model: "qwen2.5:3b-instruct-q4_K_M"
  max_tokens: 1024
  temperature: 0.7
  context_length: 15  # mesaj

# STT
stt:
  model_size: "medium"  # tiny, small, medium
  device: "cuda"
  compute_type: "int8"  # daha az VRAM
  language: "tr"

# TTS
tts:
  model: "kokoro-82m"
  device: "cpu"  # VRAM tasarrufu
  voice: "af_sky"

# Wake Word
wake_word:
  enabled: true
  keyword: "jarvis"  # veya "computer", "hey google"
  sensitivity: 0.5
```

---

## ğŸ® Komutlar

### Console Modu KomutlarÄ±

| Komut | AÃ§Ä±klama |
|-------|----------|
| `/voice` | Sesli mod (mikrofon ile konuÅŸ) |
| `/image <path>` | Resim analizi |
| `/search <query>` | Web aramasÄ± |
| `/clear` | GeÃ§miÅŸi temizle |
| `/exit` | Ã‡Ä±kÄ±ÅŸ |

---

## ğŸ“Š Performans Beklentileri

| Ä°ÅŸlem | RTX 2060 Super | AÃ§Ä±klama |
|-------|----------------|----------|
| Ä°lk BaÅŸlatma | 15-20 sn | Model yÃ¼kleme |
| Qwen2.5 Cevap | 3-5 sn | 100 kelime |
| Whisper STT | 0.3-0.5 sn | 5 sn konuÅŸma |
| Moondream GÃ¶rsel | 2-3 sn | Tek resim |
| Kokoro TTS | 2-3 sn | 1 cÃ¼mle |
| Wake Word | <0.1 sn | AnÄ±nda |
| **VRAM KullanÄ±mÄ±** | **3-4 GB** | Peak |

---

## ğŸ§ª Testler

```bash
# VRAM optimizasyon testi
python tests/test_vram.py

# LLM testleri
python tests/test_llm.py

# Audio testleri
python tests/test_audio.py

# Performans benchmark
python tests/benchmark.py
```

---

## ğŸ› Troubleshooting

### âŒ "CUDA out of memory"

```yaml
# config/settings.yaml
hardware:
  gpu_memory_limit: 6.0  # Daha dÃ¼ÅŸÃ¼k

llm:
  model: "qwen2.5:1.5b-instruct-q4_K_M"  # Daha kÃ¼Ã§Ã¼k model
```

### âŒ "Ollama connection refused"

```bash
# Ollama servisini baÅŸlat
ollama serve

# Veya Windows Services'tan "Ollama" baÅŸlat
```

### âŒ Ses kalitesi kÃ¶tÃ¼

```yaml
# config/settings.yaml
stt:
  vad_filter: true  # GÃ¼rÃ¼ltÃ¼ filtreleme
  model_size: "large-v2"  # Daha iyi model
```

---

## ğŸ“ Lisans

Apache License 2.0 - Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

**KullanÄ±lan TÃ¼m BileÅŸenler Ticari KullanÄ±ma Uygun:**
- Qwen2.5: Apache 2.0 âœ…
- Moondream: Apache 2.0 âœ…
- Whisper: MIT âœ…
- Kokoro: Apache 2.0 âœ…
- Porcupine: Apache 2.0 âœ…
- Ollama: MIT âœ…

---

## ğŸ™ KatkÄ±da Bulunma

Pull request'ler memnuniyetle karÅŸÄ±lanÄ±r!

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. Commit edin (`git commit -m 'Add amazing feature'`)
4. Push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

---

## ğŸ“§ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in GitHub Issues kullanabilirsiniz.

---

## ğŸŒŸ TeÅŸekkÃ¼rler

- [Qwen Team](https://github.com/QwenLM/Qwen2.5) - LLM
- [Moondream](https://moondream.ai/) - VLM
- [OpenAI](https://github.com/openai/whisper) - Whisper
- [Ollama](https://ollama.com/) - Model Runtime
- [Picovoice](https://picovoice.ai/) - Wake Word

---

**ğŸ¤ Happy Coding!**
